{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7440128,"sourceType":"datasetVersion","datasetId":4330075},{"sourceId":7454512,"sourceType":"datasetVersion","datasetId":4339038}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- cnn: https://pyimagesearch.com/2021/07/19/pytorch-training-your-first-convolutional-neural-network-cnn/\n- differentSize: https://learnopencv.com/fully-convolutional-image-classification-on-arbitrary-sized-image/\n- spp implementatiojn: https://github.com/revidee/pytorch-pyramid-pooling;;;; https://github.com/yifanjiang19/sppnet-pytorch/tree/master","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle\nimport os\n\n## for visualisation\nimport matplotlib.pyplot as plt\n\n## for dataset\nimport torch\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-02-08T13:57:06.385835Z","iopub.execute_input":"2024-02-08T13:57:06.386744Z","iopub.status.idle":"2024-02-08T13:57:11.043025Z","shell.execute_reply.started":"2024-02-08T13:57:06.386701Z","shell.execute_reply":"2024-02-08T13:57:11.041947Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## extraction of data from files ","metadata":{}},{"cell_type":"code","source":"## extracting the annotations\ncsvPath = '/kaggle/input/d/sabyasachi96/profiling-of-spheroids/AllAnnotatedCSVDic.pickle'\nwith open(csvPath, 'rb') as f:\n    data = pickle.load(f)\n    \ncomplete_df = pd.DataFrame()\nfor keys in data.keys():\n    print(keys)\n#     df = data[keys]\n    complete_df = pd.concat([complete_df, data[keys]])\n\ncomplete_df['Location_tags'] = (complete_df.iloc[:, 4:6] == 1).idxmax(1)    \nLocation_tags = complete_df['Location_tags'].str.split(\"-\",  n=3, expand=True)\ncomplete_df['Location_tags'] = complete_df['Location_tags'].str.split(\"-\",  n=3, expand=True)[2]\n\ncomplete_df['Outline_tags'] = (complete_df.iloc[:, 8:10] == 1).idxmax(1)\nOutline_tags = complete_df['Outline_tags'].str.split(\"-\",  n=3, expand=True)\ncomplete_df['Outline_tags'] = complete_df['Outline_tags'].str.split(\"-\",  n=3, expand=True)[2]\n\ncomplete_df['Cysticity_tags'] = (complete_df.iloc[:, 10:13] == 1).idxmax(1)\nCysticity_tags = complete_df['Cysticity_tags'].str.split(\"-\",  n=2, expand=True)\ncomplete_df['Cysticity_tags'] = complete_df['Cysticity_tags'].str.replace(r'\\-|\\d+', '', regex=True)\n\ncomplete_df['Shape_tags'] = (complete_df.iloc[:, 13:16] == 1).idxmax(1)\nShape_tags = complete_df['Shape_tags'].str.split(\"-\",  n=3, expand=True)[2]\ncomplete_df['Shape_tags'] = complete_df['Shape_tags'].str.split(\"-\",  n=3, expand=True)[2]\n\ncomplete_df.drop(['changed'], axis=1, inplace = True)\ncomplete_df.drop(complete_df.iloc[:, 3:15], inplace=True, axis=1)\n\nprint(len(complete_df))\ncomplete_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T13:57:11.044981Z","iopub.execute_input":"2024-02-08T13:57:11.045631Z","iopub.status.idle":"2024-02-08T13:57:11.128948Z","shell.execute_reply.started":"2024-02-08T13:57:11.045589Z","shell.execute_reply":"2024-02-08T13:57:11.128158Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"20220714_JK_d1_diff_isRASb1_corr_13_5_uM_CHIR_220018_p17_6mio_dish_2.tiff.csv\n20230530_JK_BRAF_mc_8_dish_2_d20_230015.tif.csv\n20230530_JK_BRAF_corr_5_dish_2_d20_230015.tif.csv\n20230412_JK_diff_230011_RIT1a_corr_8_dish_1_d0.tiff.csv\n20230412_JK_diff_230011_RIT1a_corr_8_dish_3_d0.tiff.csv\n20230530_JK_BRAF_mc_8_dish_1_d20_230015.tif.csv\n20230412_JK_diff_230011_RIT1a_corr_8_dish_2_d0.tiff.csv\n20230530_JK_BRAF_corr_5_dish_1_d20_230015.tif.csv\n32\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                             example  1-(EB) Embryonic Body  \\\n0  spheroid4_20220714_JK_d1_diff_isRASb1_corr_13_...                  False   \n1  spheroid2_20220714_JK_d1_diff_isRASb1_corr_13_...                   True   \n2  spheroid3_20220714_JK_d1_diff_isRASb1_corr_13_...                  False   \n3  spheroid1_20220714_JK_d1_diff_isRASb1_corr_13_...                  False   \n0  spheroid2_20230530_JK_BRAF_mc_8_dish_2_d20_230...                  False   \n\n   1-(NEB) non-Embryonic Body  7-Can't determine Location_tags Outline_tags  \\\n0                       False               True          Edge       Smooth   \n1                       False               True          Edge       Smooth   \n2                       False               True          Edge       Smooth   \n3                       False               True          Edge       Smooth   \n0                       False               True          Edge       Smooth   \n\n  Cysticity_tags Shape_tags  \n0      Noncystic      Round  \n1      Noncystic      Round  \n2      Noncystic      Round  \n3      Noncystic      Round  \n0      Noncystic      Round  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example</th>\n      <th>1-(EB) Embryonic Body</th>\n      <th>1-(NEB) non-Embryonic Body</th>\n      <th>7-Can't determine</th>\n      <th>Location_tags</th>\n      <th>Outline_tags</th>\n      <th>Cysticity_tags</th>\n      <th>Shape_tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>spheroid4_20220714_JK_d1_diff_isRASb1_corr_13_...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>Edge</td>\n      <td>Smooth</td>\n      <td>Noncystic</td>\n      <td>Round</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>spheroid2_20220714_JK_d1_diff_isRASb1_corr_13_...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>Edge</td>\n      <td>Smooth</td>\n      <td>Noncystic</td>\n      <td>Round</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spheroid3_20220714_JK_d1_diff_isRASb1_corr_13_...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>Edge</td>\n      <td>Smooth</td>\n      <td>Noncystic</td>\n      <td>Round</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>spheroid1_20220714_JK_d1_diff_isRASb1_corr_13_...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>Edge</td>\n      <td>Smooth</td>\n      <td>Noncystic</td>\n      <td>Round</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>spheroid2_20230530_JK_BRAF_mc_8_dish_2_d20_230...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>Edge</td>\n      <td>Smooth</td>\n      <td>Noncystic</td>\n      <td>Round</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sum(complete_df[\"7-Can't determine\"].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-02-08T14:02:24.851367Z","iopub.execute_input":"2024-02-08T14:02:24.851769Z","iopub.status.idle":"2024-02-08T14:02:24.861090Z","shell.execute_reply.started":"2024-02-08T14:02:24.851738Z","shell.execute_reply":"2024-02-08T14:02:24.859775Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"32"},"metadata":{}}]},{"cell_type":"code","source":"\nprint(len(complete_df))\nprint(sum(complete_df[\"7-Can't determine\"]))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-08T14:00:36.080456Z","iopub.execute_input":"2024-02-08T14:00:36.080917Z","iopub.status.idle":"2024-02-08T14:00:36.088297Z","shell.execute_reply.started":"2024-02-08T14:00:36.080880Z","shell.execute_reply":"2024-02-08T14:00:36.087052Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"32\n14\n","output_type":"stream"}]},{"cell_type":"code","source":"complete_df[complete_df['example'] == 'spheroid5_20220714_JK_d1_diff_isRASb1_corr_13_5_uM_CHIR_220018_p17_6mio_dish_2.tiff.png']","metadata":{"execution":{"iopub.status.busy":"2024-01-23T23:21:37.738138Z","iopub.execute_input":"2024-01-23T23:21:37.738750Z","iopub.status.idle":"2024-01-23T23:21:37.749886Z","shell.execute_reply.started":"2024-01-23T23:21:37.738709Z","shell.execute_reply":"2024-01-23T23:21:37.748853Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [example, 1-(EB) Embryonic Body, 1-(NEB) non-Embryonic Body, 7-Can't determine, Location_tags, Outline_tags, Cysticity_tags, Shape_tags]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example</th>\n      <th>1-(EB) Embryonic Body</th>\n      <th>1-(NEB) non-Embryonic Body</th>\n      <th>7-Can't determine</th>\n      <th>Location_tags</th>\n      <th>Outline_tags</th>\n      <th>Cysticity_tags</th>\n      <th>Shape_tags</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"names = complete_df['example']\nfor name in names:\n    print(name)\n    break\n\nx = [complete_df.loc[complete_df['example'] == 'spheroid4_20220714_JK_d1_diff_isRASb1_corr_13_5_uM_CHIR_220018_p17_6mio_dish_2.tiff.png']['Outline_tags'].tolist(),\n     complete_df.loc[complete_df['example'] == 'spheroid4_20220714_JK_d1_diff_isRASb1_corr_13_5_uM_CHIR_220018_p17_6mio_dish_2.tiff.png']['Cysticity_tags'].tolist(),\n     complete_df.loc[complete_df['example'] == 'spheroid4_20220714_JK_d1_diff_isRASb1_corr_13_5_uM_CHIR_220018_p17_6mio_dish_2.tiff.png']['Shape_tags'].tolist()]\n\nx = np.concatenate(x)\nx\n     \n","metadata":{"execution":{"iopub.status.busy":"2024-01-23T23:20:42.888305Z","iopub.execute_input":"2024-01-23T23:20:42.888708Z","iopub.status.idle":"2024-01-23T23:20:42.900261Z","shell.execute_reply.started":"2024-01-23T23:20:42.888679Z","shell.execute_reply":"2024-01-23T23:20:42.899101Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"spheroid4_20220714_JK_d1_diff_isRASb1_corr_13_5_uM_CHIR_220018_p17_6mio_dish_2.tiff.png\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array(['Smooth', 'Noncystic', 'Round'], dtype='<U9')"},"metadata":{}}]},{"cell_type":"code","source":"# complete_df.head()\n# names = list(complete_df['example'])\n# i = 0\n# j = 0 \n# for name in names:\n#     i = i+1\n#     nEb = complete_df[complete_df['example'] == name][\"1-(NEB) non-Embryonic Body\"].bool()\n#     Eb = complete_df[complete_df['example'] == name][\"1-(EB) Embryonic Body\"].bool()\n#     cantDetermine = complete_df[complete_df['example'] == name][\"7-Can't determine\"].bool()\n# #     print('\\n', name, f'\\n{i}', cantDetermine, nEb, Eb)\n    \n#     if (cantDetermine == False) and (nEb == False) and (Eb == True):\n#         j = j+1\n#         print('Embryonic body - annotated - used for training')\n#         print(j, 'Total training data')\n#     elif (cantDetermine == False) & (nEb == True) & (Eb == False):\n#         continue\n#         print('Non Embryonic body - not annotated - skipped')\n#     elif (cantDetermine == True) & (nEb == False) & (Eb == False):\n#         continue\n#         print('Less area visible - not annotated - skipped')\n#     elif (cantDetermine == True) & (nEb == False) & (Eb == True):\n#         continue\n#         print('Less area visible - partially annotated - skipped')\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-23T23:17:35.229571Z","iopub.execute_input":"2024-01-23T23:17:35.230046Z","iopub.status.idle":"2024-01-23T23:17:35.236256Z","shell.execute_reply.started":"2024-01-23T23:17:35.230011Z","shell.execute_reply":"2024-01-23T23:17:35.235159Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"complete_df[complete_df['example'] == 'spheroid4_20220714_JK_d1_diff_isRASb1_corr_13_5_uM_CHIR_220018_p17_6mio_dish_2.tiff.png' ][\"1-(NEB) non-Embryonic Body\"]\n","metadata":{"execution":{"iopub.status.busy":"2024-01-23T23:17:37.402781Z","iopub.execute_input":"2024-01-23T23:17:37.404230Z","iopub.status.idle":"2024-01-23T23:17:37.413432Z","shell.execute_reply.started":"2024-01-23T23:17:37.404181Z","shell.execute_reply":"2024-01-23T23:17:37.412481Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0    False\nName: 1-(NEB) non-Embryonic Body, dtype: bool"},"metadata":{}}]},{"cell_type":"markdown","source":"## checking ","metadata":{}},{"cell_type":"code","source":"def readData(imgPath, df = None):\n    \"\"\"Reads and creates a dictionary of cropped Images\n    same as ----> def croppedSpheroidImg(spheroidInfo, df = None):\n    \"\"\" \n    imageList = {}\n    sample = {}\n    print('CSV data file length:- ', len(df))\n  \n    for i, image_name in enumerate(sorted(os.listdir(imgPath))):\n        if ((image_name.split('.')[1] == 'tif') or (image_name.split('.')[1] == 'tiff')):\n            path = imgPath + image_name\n            with open (path, 'rb') as f: ## rb stands for raw binary\n                data = pickle.load(f)\n            combinedImage = data[0]\n            # mask = data[1]\n            # markedImage = data[2]\n            spheroidInfoDic = data[3]\n            #print(i,\"_total big spheroid images_\", len(spheroidInfoDic))\n            names = list(df['example'])\n            \n            ## filltering the croppedImages based on CSV file \n            for key in spheroidInfoDic:     \n                croppedName = key + '.png'  # example names\n                if croppedName not in  names:\n#                     print(f'{croppedName} is not present for development purpose')\n                    continue\n                else:\n                    nEb = df[df['example'] == croppedName][\"1-(NEB) non-Embryonic Body\"].bool()\n                    Eb = df[df['example'] == croppedName][\"1-(EB) Embryonic Body\"].bool()\n                    cantDetermine = df[df['example'] == croppedName][\"7-Can't determine\"].bool()\n    \n                    if (cantDetermine == False) and (nEb == False) and (Eb == True):\n                        # print('\\nEmbryonic body - annotated - used for training')\n                        croppedImage = spheroidInfoDic[key][2]\n                        imageList[key] = croppedImage\n                        tags = [df.loc[df['example'] == croppedName]['Outline_tags'].tolist(),\n                                df.loc[df['example'] == croppedName]['Cysticity_tags'].tolist(),\n                                df.loc[df['example'] == croppedName]['Shape_tags'].tolist()]\n                        sample = {'image': croppedImage, 'annotations': np.concatenate(tags)}\n                        \n                    elif (cantDetermine == False) & (nEb == True) & (Eb == False):\n                        continue\n                        print('Non Embryonic body - not annotated - skipped')      \n                    elif (cantDetermine == True) & (nEb == False) & (Eb == False):\n                        continue\n                        print('Less area visible - not annotated - skipped')\n                    elif (cantDetermine == True) & (nEb == False) & (Eb == True):\n                        continue\n                        print('Less area visible - partially annotated - skipped')   \n            \n        print('Total cropped spheroids after filtering', len(imageList))\n            \n            \n    return imageList, sample\n\nimgPath = '/kaggle/input/d/sabyasachi96/profiling-of-spheroids/bigImg_spheroidDetails/'\n# imgPath = '/kaggle/input/profiling-of-spheroids/bigImg_spheroidDetails 10-44-15-277/'\nimageList, sample = readData(imgPath, df = complete_df)\n# print(len(imageList), imageList['spheroid1_20220714_JK_d1_diff_isRASb1_corr_13_5_uM_CHIR_220018_p17_6mio_dish_2.tiff'].shape)#, imageList.keys())\n# plt.imshow(imageList['spheroid1_20220714_JK_d1_diff_isRASb1_corr_13_5_uM_CHIR_220018_p17_6mio_dish_2.tiff'])","metadata":{"execution":{"iopub.status.busy":"2024-01-23T23:17:39.556832Z","iopub.execute_input":"2024-01-23T23:17:39.557239Z","iopub.status.idle":"2024-01-23T23:17:41.861796Z","shell.execute_reply.started":"2024-01-23T23:17:39.557206Z","shell.execute_reply":"2024-01-23T23:17:41.860703Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"CSV data file length:-  32\nTotal cropped spheroids after filtering 0\nTotal cropped spheroids after filtering 4\nTotal cropped spheroids after filtering 7\nTotal cropped spheroids after filtering 8\nTotal cropped spheroids after filtering 9\nTotal cropped spheroids after filtering 12\nTotal cropped spheroids after filtering 15\nTotal cropped spheroids after filtering 17\n","output_type":"stream"}]},{"cell_type":"code","source":"def plotSanityCheckImages(imgList):\n    \"\"\"create a functin to check the cropped images\"\"\"\n    \n#     print(f'Images:{img1.shape} and mask:{img2.shape} shape\\n')\n    \n#     figure, ax = plt.subplots(nrows=1, ncols=3, figsize=(10,10))\n#     ax[0].imshow(img1)\n#     ax[1].imshow(img2, cmap = 'gray')\n#     ax[2].imshow(img2 * img1, cmap = 'gray')\n\n#     ax[0].set_title(\"Image with the original channel\")\n#     ax[1].set_title(\"Original Mask\")\n#     ax[2].set_title(\"combined and made gray\")\n\n#     figure.tight_layout()\n#     figure.show()\n\n# plotSanityCheckImages(image[0], label[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset Creation for cropped images","metadata":{}},{"cell_type":"code","source":"def combinedCSV(csvPath):\n    \"\"\"\n    creates the complete csv file\n    also preprocessing of the csv file\n    \"\"\"     \n    with open(csvPath, 'rb') as f:\n        data = pickle.load(f)\n    \n    combined_df = pd.DataFrame()\n    for keys in data.keys():\n        combined_df = pd.concat([combined_df, data[keys]])\n    print(f'length of the combined df {len(combined_df)}')\n\n    combined_df['Location_tags'] = (combined_df.iloc[:, 4:6] == 1).idxmax(1)    \n    Location_tags = combined_df['Location_tags'].str.split(\"-\",  n=3, expand=True)\n    combined_df['Location_tags'] = combined_df['Location_tags'].str.split(\"-\",  n=3, expand=True)[2]\n\n    combined_df['Outline_tags'] = (combined_df.iloc[:, 8:10] == 1).idxmax(1)\n    Outline_tags = combined_df['Outline_tags'].str.split(\"-\",  n=3, expand=True)\n    combined_df['Outline_tags'] = combined_df['Outline_tags'].str.split(\"-\",  n=3, expand=True)[2]\n\n    combined_df['Cysticity_tags'] = (combined_df.iloc[:, 10:13] == 1).idxmax(1)\n    Cysticity_tags = combined_df['Cysticity_tags'].str.split(\"-\",  n=2, expand=True)\n    combined_df['Cysticity_tags'] = combined_df['Cysticity_tags'].str.replace(r'\\-|\\d+', '', regex=True)\n\n    combined_df['Shape_tags'] = (combined_df.iloc[:, 13:16] == 1).idxmax(1)\n    Shape_tags = combined_df['Shape_tags'].str.split(\"-\",  n=3, expand=True)[2]\n    combined_df['Shape_tags'] = combined_df['Shape_tags'].str.split(\"-\",  n=3, expand=True)[2]\n\n    combined_df.drop(['changed'], axis=1, inplace = True)\n    combined_df.drop(combined_df.iloc[:, 3:15], inplace=True, axis=1)\n            \n    return combined_df\n        \n        \n        \ndef croppedSpheroidImg(spheroidInfoDic, df = None):\n    \"\"\" \n    filter the images that can be determined based on df \n    returns: imageList with their annotations \n    \"\"\"\n    imgList = {}\n    names = list(df['example'])\n    print(len(names))\n    for key in spheroidInfoDic:   \n        croppedName = key + '.png'  # example names\n        if croppedName not in names:\n#             print(f'croppedName not found--> {croppedName}')\n            continue\n        else:\n            nEb = df[df['example'] == croppedName][\"1-(NEB) non-Embryonic Body\"].bool()\n            Eb = df[df['example'] == croppedName][\"1-(EB) Embryonic Body\"].bool()\n            cantDetermine = df[df['example'] == croppedName][\"7-Can't determine\"].bool()\n    \n            if (cantDetermine == False) and (nEb == False) and (Eb == True):\n                croppedImage = spheroidInfoDic[key][2]\n#                       imageList[key] = croppedImage\n                tags = [df.loc[df['example'] == croppedName]['Outline_tags'].tolist(),\n                        df.loc[df['example'] == croppedName]['Cysticity_tags'].tolist(),\n                        df.loc[df['example'] == croppedName]['Shape_tags'].tolist()]\n                imgList = {'image': croppedImage, 'annotations': np.concatenate(tags)}\n                        \n            elif (cantDetermine == False) & (nEb == True) & (Eb == False):\n                continue\n                print('Non Embryonic body - not annotated - skipped')      \n            elif (cantDetermine == True) & (nEb == False) & (Eb == False):\n                continue\n                print('Less area visible - not annotated - skipped')\n            elif (cantDetermine == True) & (nEb == False) & (Eb == True):\n                continue\n                print('Less area visible - partially annotated - skipped')   \n    return imgList","metadata":{"execution":{"iopub.status.busy":"2024-01-23T23:27:23.257799Z","iopub.execute_input":"2024-01-23T23:27:23.258188Z","iopub.status.idle":"2024-01-23T23:27:23.274688Z","shell.execute_reply.started":"2024-01-23T23:27:23.258157Z","shell.execute_reply":"2024-01-23T23:27:23.273605Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# from torchvision import datasets\n# from collections import defaultdict, deque\n# import itertools\n\n# https://discuss.pytorch.org/t/creating-custom-dataset-from-inbuilt-pytorch-datasets-along-with-data-transformations/58270\n# class Cifar5000(datasets.CIFAR10):\n#     def __init__(self, path, transforms, train=True):\n#         super().__init__(path, train, download=True)\n#         self.transforms = transforms\n#         self.n_images_per_class = 5\n#         self.n_classes = 10\n#         self.new2old_indices = self.create_idx_mapping()\n\n#     def create_idx_mapping(self):\n#         label2idx = defaultdict(lambda: deque(maxlen=self.n_images_per_class))\n#         for original_idx in range(super().__len__()):\n#             _, label = super().__getitem__(original_idx)\n#             label2idx[label].append(original_idx)\n\n#         old_idxs = set(itertools.chain(*label2idx.values()))\n#         new2old_indices = {}\n#         for new_idx, old_idx in enumerate(old_idxs):\n#             new2old_indices[new_idx] = old_idx\n\n#         return new2old_indices\n\n#     def __len__(self):\n#         return len(self.new2old_indices)\n\n#     def __getitem__(self, index):\n#         index = self.new2old_indices[index]\n#         im, label = super().__getitem__(index)\n#         return self.transforms(im), label\n\n\n# --------------------------------\n# --------------------------------\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-23T23:27:25.345588Z","iopub.execute_input":"2024-01-23T23:27:25.345961Z","iopub.status.idle":"2024-01-23T23:27:25.351294Z","shell.execute_reply.started":"2024-01-23T23:27:25.345932Z","shell.execute_reply":"2024-01-23T23:27:25.350227Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"- https://glassboxmedicine.com/2022/01/21/building-custom-image-data-sets-in-pytorch-tutorial-with-code/\n- https://stackoverflow.com/questions/62434037/python-class-dataset-how-to-concatenate-images-with-their-respective-labels-in\n","metadata":{}},{"cell_type":"code","source":"class ebDataset(Dataset):\n    def __init__ (self, imagePath, csvPath):\n        self.imagePath = imagePath\n        self.csvPath = csvPath\n        self.croppedImageList = {}\n        self.dataLength = self.create_idx_mapping()\n        \n    def create_idx_mapping(self):#, idx):\n        combined_df =  combinedCSV(self.csvPath)\n        print(len(combined_df), f'self.imagePath-->{self.imagePath}' )\n        \n        for i, image_name in enumerate(sorted(os.listdir(self.imagePath))):\n            print(f'image_name--> {image_name}')\n            if ((image_name.split('.')[1] == 'tif') or (image_name.split('.')[1] == 'tiff')):\n                path = self.imagePath + image_name\n                print(f'path--->{path}')\n                with open (path, 'rb') as f: ## rb stands for raw binary\n                    data = pickle.load(f)\n                combinedImage = data[0] ## mask = data[1], markedImg = data[2]\n                spheroidInfoDic = data[3]\n                print('spheroidInfoDic', len(spheroidInfoDic), len(combined_df))\n                imgList = croppedSpheroidImg(spheroidInfoDic, combined_df)\n                print('imgList', imgList.keys(), len(imgList))\n#                 if len(img)\n                print(f\"imgList['image']---> {imgList['image']}\")\n\n#                 for idx, img in enumerate(imgList):\n#                     print(f'idx:{idx}----img:{img}')\n#                     if idx < self.dataLength:\n#                         self.croppedImageList[idx] = img\n#                         print(f'croppedImageList-->{self.croppedImageList[0]})')\n#                         print(f'\\n{self.croppedImageList[1]}')\n#                     else:\n#                         break\n        print('total croppedImages without filtering: ', len(self.croppedImageList))\n        \n        return imgList #self.croppedImageList\n    \n    def __len__(self):\n#         length = self.\n        return self.dataLength\n#         return len(self.croppedImageList)\n    \n    def __getitem__(self, idx):\n        if idx in self.croppedImageList:\n            idx = self.croppedImageList[idx]\n            image = idx['image']\n            tags = idx['tags']\n            return image, tags\n        else: \n            raise KeyError(f\"index{idx} not in croppedImageList\")\n        \n           \nimgPath = '/kaggle/input/d/sabyasachi96/profiling-of-spheroids/bigImg_spheroidDetails/'\ncsvPath = '/kaggle/input/d/sabyasachi96/profiling-of-spheroids/AllAnnotatedCSVDic.pickle'\ndataset = ebDataset(imgPath, csvPath)\n\n# for keys in dataset:\n#     print(len(keys), keys.keys())\n#     break\n# print(len(dataset))\ndataset\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-23T23:27:26.489209Z","iopub.execute_input":"2024-01-23T23:27:26.489698Z","iopub.status.idle":"2024-01-23T23:27:26.641724Z","shell.execute_reply.started":"2024-01-23T23:27:26.489657Z","shell.execute_reply":"2024-01-23T23:27:26.639907Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"length of the combined df 32\n32 self.imagePath-->/kaggle/input/d/sabyasachi96/profiling-of-spheroids/bigImg_spheroidDetails/\nimage_name--> divided_20220714_JK_d1_diff_isRASb1_corr_13_5_uM_CHIR_220018_p17_6mio_dish_2.tiff\npath--->/kaggle/input/d/sabyasachi96/profiling-of-spheroids/bigImg_spheroidDetails/divided_20220714_JK_d1_diff_isRASb1_corr_13_5_uM_CHIR_220018_p17_6mio_dish_2.tiff\nspheroidInfoDic 103 32\n32\nimgList dict_keys([]) 0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m imgPath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/d/sabyasachi96/profiling-of-spheroids/bigImg_spheroidDetails/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     55\u001b[0m csvPath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/d/sabyasachi96/profiling-of-spheroids/AllAnnotatedCSVDic.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 56\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mebDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgPath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsvPath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# for keys in dataset:\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m#     print(len(keys), keys.keys())\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#     break\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# print(len(dataset))\u001b[39;00m\n\u001b[1;32m     62\u001b[0m dataset\n","Cell \u001b[0;32mIn[25], line 6\u001b[0m, in \u001b[0;36mebDataset.__init__\u001b[0;34m(self, imagePath, csvPath)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcsvPath \u001b[38;5;241m=\u001b[39m csvPath\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcroppedImageList \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataLength \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_idx_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[25], line 25\u001b[0m, in \u001b[0;36mebDataset.create_idx_mapping\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimgList\u001b[39m\u001b[38;5;124m'\u001b[39m, imgList\u001b[38;5;241m.\u001b[39mkeys(), \u001b[38;5;28mlen\u001b[39m(imgList))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#                 if len(img)\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgList[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]---> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mimgList\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#                 for idx, img in enumerate(imgList):\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#                     print(f'idx:{idx}----img:{img}')\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#                     if idx < self.dataLength:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#                     else:\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#                         break\u001b[39;00m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal croppedImages without filtering: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcroppedImageList))\n","\u001b[0;31mKeyError\u001b[0m: 'image'"],"ename":"KeyError","evalue":"'image'","output_type":"error"}]},{"cell_type":"code","source":"print(len(dataset))\nfor image, tags in dataset:\n    print(image)\n    #print(keys.shape)\n#     print(len(keys[0]))\n    break\n# len(dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-01-23T17:19:51.233357Z","iopub.execute_input":"2024-01-23T17:19:51.233881Z","iopub.status.idle":"2024-01-23T17:19:51.277826Z","shell.execute_reply.started":"2024-01-23T17:19:51.233843Z","shell.execute_reply":"2024-01-23T17:19:51.276004Z"},"trusted":true},"execution_count":95,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[95], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image, tags \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(image)\n","\u001b[0;31mTypeError\u001b[0m: 'dict' object cannot be interpreted as an integer"],"ename":"TypeError","evalue":"'dict' object cannot be interpreted as an integer","output_type":"error"}]},{"cell_type":"code","source":"validation_split = 2\nb = 1\ntrain_set, validation_set = torch.utils.data.random_split(dataset, [len(dataset) - len(dataset)//validation_split,\n                                                                    len(dataset)//validation_split])\ntrainLoader = DataLoader(dataset = train_set, batch_size = b, num_workers = 2, shuffle = True)\nvalidationLoader = DataLoader(dataset = validation_set, batch_size = b, num_workers = 2, shuffle =True) \nprint(f\"Total {len(train_set)} examples in the training set\")\nprint(f\"Total {len(validation_set)} examples in the validation set\")\nprint(f\"Total number of training sets: {len(trainLoader)},and validation loader {len(validationLoader)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## creating the model ","metadata":{}},{"cell_type":"code","source":"class A:\n    def __init__(self, item):\n        self.item = item\n    def __getitem__(self, index):\n        return self.item[index]\na = A([1, 2, 3,4, 5])\nprint(f\"First item: {a[0]}\")\nprint(f\"Second item: {a[1]}\")\nprint(f\"Third item: {a[2]}, {a[4]}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-23T22:56:45.851879Z","iopub.execute_input":"2024-01-23T22:56:45.852292Z","iopub.status.idle":"2024-01-23T22:56:45.859118Z","shell.execute_reply.started":"2024-01-23T22:56:45.852260Z","shell.execute_reply":"2024-01-23T22:56:45.858056Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"First item: 1\nSecond item: 2\nThird item: 3, 5\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}